{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Natural Language Processing\n",
    "---\n",
    "\n",
    "Das ist eine Zusammenfassung bzw. ein Cheatsheet zum Thema **Natural Language Processing**.<br>\n",
    "Verfasst von Manuel Neumayer.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "## Table of Contents\n",
    "<br>\n",
    "\n",
    "### 1. Basics\n",
    "* Word Vectors\n",
    "<br>\n",
    "* Co-Occurence matrix\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "In der Computerlinguistik werden Wörter in der Regel als Vektoren dargestellt, um sie maschinell verarbeiten zu können. \n",
    "Dabei können Wörter auf verschiedene Arten als Vektoren dargestellt werden, wobei die konkrete Herangehensweise ziemlich vom Anwendungsfall abhängt. \n",
    "\n",
    "<br>\n",
    "\n",
    "## Word Vectors\n",
    "#### One-Hot-Vectors\n",
    "Bei den sogenannten **One-Hot-Vectors** handelt es sich um Vektoren, die nur aus den Werten 0 und 1 bestehen.\n",
    "Diese finden meist Anwendung, wenn man gegeben einem **Vokabular V** bestehend aus n verschiedenen Wörtern und \n",
    "einer **Dokumentensammlung D** für jedes Dokument d speichern möchte, ob das jeweilige Wort in Dokument d vorkommt oder nicht.\n",
    "<br>\n",
    "Dabei bestehen die One-Hot-Vectors aus insgesamt n Komponenten (Größe des Vokabulars), wobei der Wert der jeweiligen Vektorkomponente\n",
    "1 ist, wenn das Wort in Dokument d vorkommt und 0 wenn nicht.\n",
    "<br>\n",
    "<br>\n",
    "\"Stapelt\" man die One-Hot-Vectors aller Dokumente, ergibt sich eine Matrix mit N Zeilen und K Spalten, wobei N die Anzahl der Dokumente\n",
    "und K die Vokabulargröße ist. Aus dieser kann man dann direkt ablesen, welche Wörter in welchen Dokumenten vorkommen.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Count-based Vectors\n",
    "Im Gegensatz zu den One-Hot-Vectors können hier die Vektorkomponenten verschiedene Werte >= 0 annehmen. Die Herangehensweise ist die selbe,\n",
    "jedoch wird für jedes Wort nun nicht gespeichert, ob es vorkommt oder nicht, sondern wie oft. Somit lässt sich aus der Designmatrix später ablesen,\n",
    "welche Wörter **wie oft** in welchen Dokumenten vorkommen.++\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Context-based Word Vectors\n",
    "Für bestimmte NLP Probleme lässt sich das Konzept auch insofern erweitern, dass man für jedes Wort dessen Kontext speichert.\n",
    "Dabei wird eine bestimmte Fensterlänge n festgelegt, und für jedes Wort w(i) im Vokabular wird gespeichert, welches Wort w(j) in der \n",
    "n-Umgebung von Wort w(i) vorkommt. Dies ist wichtig, da sich herausgestellt hat, dass die Bedeutung eines Wortes maßgeblich dadurch\n",
    "bestimmt wird, welche Wörter in seiner Umgebung / in seinem Kontext vorkommen. \n",
    "<br>\n",
    "Dies lässt sich dann in einer Co-Occurence-Matrix darstellen, \n",
    "die die Form V x V besitzt (V = Vokabulargröße).\n",
    "\n",
    "<br>\n",
    "\n",
    "## Co-Occurence-Matrix\n",
    "Eine Co-Occurence_Matrix für das Vokabular V = { all, that, glitters, is, not, gold, well, ends }, der Fenstergröße n = 1 und den zwei Dokumenten:\n",
    "<br>\n",
    "<br>\n",
    "Document 1: \"all that glitters is not gold\"\n",
    "\n",
    "Document 2: \"all is well that ends well\"\n",
    "\n",
    "würde somit folgendermaßen aussehen:\n",
    "<br>\n",
    "\n",
    "|     *    | `<START>` | all | that | glitters | is   | not  | gold  | well | ends | `<END>` |\n",
    "|----------|-------|-----|------|----------|------|------|-------|------|------|-----|\n",
    "| `<START>`    | 0     | 2   | 0    | 0        | 0    | 0    | 0     | 0    | 0    | 0   |\n",
    "| all      | 2     | 0   | 1    | 0        | 1    | 0    | 0     | 0    | 0    | 0   |\n",
    "| that     | 0     | 1   | 0    | 1        | 0    | 0    | 0     | 1    | 1    | 0   |\n",
    "| glitters | 0     | 0   | 1    | 0        | 1    | 0    | 0     | 0    | 0    | 0   |\n",
    "| is       | 0     | 1   | 0    | 1        | 0    | 1    | 0     | 1    | 0    | 0   |\n",
    "| not      | 0     | 0   | 0    | 0        | 1    | 0    | 1     | 0    | 0    | 0   |\n",
    "| gold     | 0     | 0   | 0    | 0        | 0    | 1    | 0     | 0    | 0    | 1   |\n",
    "| well     | 0     | 0   | 1    | 0        | 1    | 0    | 0     | 0    | 1    | 1   |\n",
    "| ends     | 0     | 0   | 1    | 0        | 0    | 0    | 0     | 1    | 0    | 0   |\n",
    "| `<END>`      | 0     | 0   | 0    | 0        | 0    | 0    | 1     | 1    | 0    | 0   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
